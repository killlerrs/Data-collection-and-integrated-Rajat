{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076b9dc0-dd39-4a2e-a139-8f096c839bf2",
   "metadata": {},
   "source": [
    "## Integrate Data from Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bf7e74-245c-49ec-9641-492721f415bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DateTime  Junction  Vehicles           ID  Temperature (°C)  \\\n",
      "0 2015-11-01 00:00:00         1        15  20151101001                24   \n",
      "1 2015-11-01 01:00:00         1        13  20151101011                23   \n",
      "2 2015-11-01 02:00:00         1        10  20151101021                23   \n",
      "3 2015-11-01 03:00:00         1         7  20151101031                22   \n",
      "4 2015-11-01 09:00:00         1        11  20151101091                25   \n",
      "\n",
      "   Precipitation (mm)  Humidity (%)  Wind Speed (km/h)          Event Type  \\\n",
      "0                   0            80                 12  Religious Festival   \n",
      "1                   0            78                 10                   -   \n",
      "2                   0            77                  8                   -   \n",
      "3                   0            75                  7                   -   \n",
      "4                   0            85                 14      Public Holiday   \n",
      "\n",
      "    Event Name  \n",
      "0  Ganga Aarti  \n",
      "1            -  \n",
      "2            -  \n",
      "3            -  \n",
      "4       Diwali  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from separate sources (example file paths)\n",
    "traffic_data = pd.read_excel(r'C:\\Users\\Rajat\\Downloads\\traffic_data.xlsx')  # Replace with actual file path\n",
    "weather_data = pd.read_excel(r'C:\\Users\\Rajat\\Downloads\\weather_data.xlsx')  # Replace with actual file path\n",
    "event_data = pd.read_excel(r'C:\\Users\\Rajat\\Downloads\\event_data.xlsx')      # Replace with actual file path\n",
    "\n",
    "\n",
    "# Ensure that the DateTime column is in datetime format for all datasets\n",
    "traffic_data['DateTime'] = pd.to_datetime(traffic_data['DateTime'], format='%d/%m/%y %H:%M')\n",
    "weather_data['DateTime'] = pd.to_datetime(weather_data['DateTime'], format='%d/%m/%y %H:%M')\n",
    "event_data['DateTime'] = pd.to_datetime(event_data['DateTime'], format='%d/%m/%y %H:%M')\n",
    "\n",
    "# Merge the traffic and weather data on 'DateTime' using an outer join to retain all data\n",
    "merged_data = pd.merge(traffic_data, weather_data, on='DateTime', how='outer')\n",
    "\n",
    "# Merge the result with event data on 'DateTime'\n",
    "final_merged_data = pd.merge(merged_data, event_data, on='DateTime', how='outer')\n",
    "\n",
    "# Save the final integrated data to Excel\n",
    "final_merged_data.to_excel('integrated_data.xlsx', index=False)\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(final_merged_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de37f16-0426-4f30-80ab-f7931f78d248",
   "metadata": {},
   "source": [
    "## Handle Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d8b617-b5be-42f5-8edd-fd97c3225ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " DateTime              0\n",
      "Junction              0\n",
      "Vehicles              0\n",
      "ID                    0\n",
      "Temperature (°C)      0\n",
      "Precipitation (mm)    0\n",
      "Humidity (%)          0\n",
      "Wind Speed (km/h)     0\n",
      "Event Type            0\n",
      "Event Name            0\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the merged data (from Step 2)\n",
    "file_path = r'C:\\Users\\Rajat\\Downloads\\traffic 5.xlsx'  # Replace with the path to your merged dataset\n",
    "merged_data = pd.read_excel(file_path)\n",
    "\n",
    "# Step 1: Check for missing values\n",
    "missing_values = merged_data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# Step 2: Impute missing values for numerical columns\n",
    "merged_data['Temperature (°C)'] = merged_data['Temperature (°C)'].fillna(merged_data['Temperature (°C)'].mean())\n",
    "merged_data['Precipitation (mm)'] = merged_data['Precipitation (mm)'].fillna(merged_data['Precipitation (mm)'].mean())\n",
    "merged_data['Humidity (%)'] = merged_data['Humidity (%)'].fillna(merged_data['Humidity (%)'].mean())\n",
    "merged_data['Wind Speed (km/h)'] = merged_data['Wind Speed (km/h)'].fillna(merged_data['Wind Speed (km/h)'].mean())\n",
    "\n",
    "# Impute missing values for categorical columns\n",
    "merged_data['Event Type'] = merged_data['Event Type'].fillna('No Event')\n",
    "merged_data['Event Name'] = merged_data['Event Name'].fillna('No Event')\n",
    "\n",
    "# Step 3: Check for duplicates\n",
    "duplicates = merged_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "\n",
    "# Step 4: Normalize numerical columns (optional, but recommended)\n",
    "scaler = MinMaxScaler()\n",
    "merged_data[['Temperature (°C)', 'Vehicles', 'Precipitation (mm)', 'Humidity (%)', 'Wind Speed (km/h)']] = scaler.fit_transform(\n",
    "    merged_data[['Temperature (°C)', 'Vehicles', 'Precipitation (mm)', 'Humidity (%)', 'Wind Speed (km/h)']]\n",
    ")\n",
    "\n",
    "# Save the cleaned and normalized data to Excel\n",
    "cleaned_file_path = 'step_3_cleaned_and_normalized_data.xlsx'\n",
    "merged_data.to_excel(cleaned_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f34de-d6e4-4554-8f06-45faa1a76755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
